from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import aiofiles
import asyncio
import uuid
from datetime import datetime
from pathlib import Path
import logging
from typing import List, Dict, Any, Optional
import sys
import json
import re
import aiohttp
import pytz
from urllib.parse import unquote
import psycopg
from psycopg_pool import AsyncConnectionPool
from contextlib import asynccontextmanager
from logging.handlers import RotatingFileHandler

# í ì‹œìŠ¤í…œ ì¶”ê°€ imports
import asyncio
from asyncio import Queue, Event
from dataclasses import dataclass
from typing import Callable
import time

# í ì‘ì—… ë°ì´í„° í´ë˜ìŠ¤
@dataclass
class QueueTask:
    task_id: str
    user_id: str
    username: str
    image_urls: list
    data: dict
    result_future: asyncio.Future
    created_at: float

# í ì‹œìŠ¤í…œ ì„¤ì •
DB_WRITE_QUEUE = Queue(maxsize=10000)  # ìµœëŒ€ 10,000ê°œ ì‘ì—… ëŒ€ê¸°
QUEUE_WORKERS = 10  # DB ì“°ê¸° ì›Œì»¤ ìˆ˜
BATCH_SIZE = 10    # ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
BATCH_TIMEOUT = 0.5  # ë°°ì¹˜ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

# í ì›Œì»¤ ìƒíƒœ ê´€ë¦¬
queue_workers_running = False
worker_tasks = []

async def start_queue_workers():
    """í ì›Œì»¤ë“¤ ì‹œì‘"""
    global queue_workers_running, worker_tasks
    if queue_workers_running:
        return
    
    queue_workers_running = True
    worker_tasks = []
    
    for i in range(QUEUE_WORKERS):
        task = asyncio.create_task(db_queue_worker(f"worker-{i}"))
        worker_tasks.append(task)
    
    logger.info(f"í ì›Œì»¤ {QUEUE_WORKERS}ê°œ ì‹œì‘ë¨")

async def stop_queue_workers():
    """í ì›Œì»¤ë“¤ ì¢…ë£Œ"""
    global queue_workers_running, worker_tasks
    queue_workers_running = False
    
    # ëª¨ë“  ì›Œì»¤ ì‘ì—… ì·¨ì†Œ
    for task in worker_tasks:
        task.cancel()
    
    # ì›Œì»¤ë“¤ì´ ì™„ì „íˆ ì¢…ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
    if worker_tasks:
        await asyncio.gather(*worker_tasks, return_exceptions=True)
    
    worker_tasks = []
    logger.info("ëª¨ë“  í ì›Œì»¤ ì¢…ë£Œë¨")

async def db_queue_worker(worker_name: str):
    """DB ì“°ê¸° ì „ìš© í ì›Œì»¤"""
    logger.info(f"í ì›Œì»¤ {worker_name} ì‹œì‘")
    
    while queue_workers_running:
        try:
            # ë°°ì¹˜ë¡œ ì‘ì—…ë“¤ ìˆ˜ì§‘
            batch = []
            batch_start_time = time.time()
            
            # ì²« ë²ˆì§¸ ì‘ì—… ëŒ€ê¸° (ë¸”ë¡œí‚¹)
            try:
                first_task = await asyncio.wait_for(
                    DB_WRITE_QUEUE.get(), 
                    timeout=5.0
                )
                batch.append(first_task)
            except asyncio.TimeoutError:
                continue  # íƒ€ì„ì•„ì›ƒë˜ë©´ ë‹¤ì‹œ ì‹œë„
            
            # ì¶”ê°€ ì‘ì—…ë“¤ ìˆ˜ì§‘ (ë°°ì¹˜ í¬ê¸°ë‚˜ ì‹œê°„ ì œí•œê¹Œì§€)
            while (len(batch) < BATCH_SIZE and 
                   time.time() - batch_start_time < BATCH_TIMEOUT):
                try:
                    task = await asyncio.wait_for(
                        DB_WRITE_QUEUE.get(), 
                        timeout=0.1
                    )
                    batch.append(task)
                except asyncio.TimeoutError:
                    break  # ë” ì´ìƒ ì‘ì—…ì´ ì—†ìœ¼ë©´ ë°°ì¹˜ ì²˜ë¦¬ ì§„í–‰
            
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
            if batch:
                await process_batch(worker_name, batch)
                
        except asyncio.CancelledError:
            logger.info(f"í ì›Œì»¤ {worker_name} ì·¨ì†Œë¨")
            break
        except Exception as e:
            logger.error(f"í ì›Œì»¤ {worker_name} ì—ëŸ¬: {str(e)}")
            await asyncio.sleep(1)  # ì—ëŸ¬ ë°œìƒ ì‹œ ì ì‹œ ëŒ€ê¸°
    
    logger.info(f"í ì›Œì»¤ {worker_name} ì¢…ë£Œ")

async def process_batch(worker_name: str, batch: list):
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ DB ì‘ì—… ì²˜ë¦¬"""
    logger.info(f"{worker_name}: ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ ({len(batch)}ê°œ ì‘ì—…)")
    
    for task in batch:
        try:
            # ê°œë³„ ì‘ì—… ì²˜ë¦¬
            result = await process_single_task(task)
            
            # ê²°ê³¼ë¥¼ Futureì— ì„¤ì •
            if not task.result_future.done():
                task.result_future.set_result(result)
                
        except Exception as e:
            # ì—ëŸ¬ë¥¼ Futureì— ì„¤ì •
            if not task.result_future.done():
                task.result_future.set_exception(e)
            logger.error(f"{worker_name}: ì‘ì—… ì²˜ë¦¬ ì‹¤íŒ¨ - {task.task_id}: {str(e)}")
        finally:
            # íì—ì„œ ì‘ì—… ì™„ë£Œ í‘œì‹œ
            DB_WRITE_QUEUE.task_done()
    
    logger.info(f"{worker_name}: ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ ({len(batch)}ê°œ ì‘ì—…)")

# í ì›Œì»¤ì—ì„œ ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
async def process_single_task(task: QueueTask) -> dict:
    """ê°œë³„ ì‘ì—… ì²˜ë¦¬ (ì‹¤ì œ DB ì €ì¥)"""
    start_time = time.time()
    try:
        logger.info(f"ì‘ì—… ì‹œì‘: {task.task_id} (ëŒ€ê¸°ì‹œê°„: {start_time - task.created_at:.2f}ì´ˆ)")
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        downloaded_images = []
        saved_files = []
        
        async with aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30)
        ) as session:
            download_tasks = [
                download_kakao_image(session, url, task.user_id, task.username) 
                for url in task.image_urls
            ]
            
            if download_tasks:
                results = await asyncio.gather(*download_tasks, return_exceptions=True)
                
                for i, result in enumerate(results):
                    if isinstance(result, Exception):
                        logger.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ {i+1}: {str(result)}")
                        downloaded_images.append({
                            "status": "error",
                            "error": str(result)[:100],
                            "url": task.image_urls[i] if i < len(task.image_urls) else "unknown"
                        })
                    else:
                        downloaded_images.append(result)
                        if result.get("status") == "success":
                            saved_files.append(result.get("file_path"))
        
        # ì„±ê³µí•œ ë‹¤ìš´ë¡œë“œ ìˆ˜ ê³„ì‚°
        success_count = sum(1 for img in downloaded_images if img.get("status") == "success")
        
        # ëª¨ë“  ì´ë¯¸ì§€ê°€ ì„±ê³µí•˜ì§€ ì•Šìœ¼ë©´ ë¡¤ë°±
        if task.image_urls and success_count != len(task.image_urls):
            await cleanup_files(saved_files)
            logger.warning(f"ì‘ì—… ì‹¤íŒ¨: {task.task_id} - ë‹¤ìš´ë¡œë“œ {success_count}/{len(task.image_urls)}")
            return {
                "success": False,
                "error": "ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨",
                "success_count": success_count,
                "total_count": len(task.image_urls),
                "saved_to_db_count": 0
            }
        
        # DB ì €ì¥ (ì¬ì‹œë„ ë¡œì§ ê°„ì†Œí™”)
        saved_to_db_count = 0
        if success_count > 0:
            try:
                async with db_pool.connection() as conn:
                    async with conn.transaction():
                        for i, img in enumerate(downloaded_images):
                            if img.get("status") == "success":
                                db_saved = await save_image_upload_to_db_in_transaction(
                                    conn=conn,
                                    username=task.username,
                                    original_url=task.image_urls[i],
                                    user_id=task.user_id,
                                    image_data=img
                                )
                                
                                if not db_saved:
                                    raise Exception(f"DB ì €ì¥ ì‹¤íŒ¨: ì´ë¯¸ì§€ {i+1}")
                        
                        saved_to_db_count = success_count
                        
            except Exception as db_error:
                await cleanup_files(saved_files)
                return {
                    "success": False,
                    "error": f"DB ì €ì¥ ì‹¤íŒ¨",
                    "success_count": 0,
                    "total_count": len(task.image_urls),
                    "saved_to_db_count": 0
                }
        
        processing_time = time.time() - start_time
        
        return {
            "success": True,
            "success_count": success_count,
            "total_count": len(task.image_urls),
            "saved_to_db_count": saved_to_db_count,
            "processing_time": processing_time
        }
        
    except Exception as e:
        await cleanup_files(saved_files)
        return {
            "success": False,
            "error": str(e)[:100],  # ì—ëŸ¬ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
            "success_count": 0,
            "total_count": len(task.image_urls) if task.image_urls else 0,
            "saved_to_db_count": 0
        }

async def submit_to_queue(user_id: str, username: str, image_urls: list, data: dict) -> dict:
    """ì‘ì—…ì„ íì— ì œì¶œí•˜ê³  ê²°ê³¼ ëŒ€ê¸°"""
    # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì²˜ë¦¬
    if DB_WRITE_QUEUE.qsize() >= DB_WRITE_QUEUE.maxsize * 0.8:
        logger.warning(f"íê°€ ê±°ì˜ ê°€ë“ì°¸: {DB_WRITE_QUEUE.qsize()}/{DB_WRITE_QUEUE.maxsize}")
        return {
            "success": False,
            "error": "ì„œë²„ê°€ ê³¼ë¶€í•˜ ìƒíƒœì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        }
    
    # ë¹ˆ ì´ë¯¸ì§€ URL ì²´í¬
    if not image_urls:
        return {
            "success": False,
            "error": "ì´ë¯¸ì§€ URL ì—†ìŒ"
        }
    
    # ì‘ì—… ìƒì„±
    task_id = f"{user_id[:8]}_{int(time.time() * 1000)}"
    result_future = asyncio.Future()
    
    task = QueueTask(
        task_id=task_id,
        user_id=user_id,
        username=username,
        image_urls=image_urls,
        data=data,
        result_future=result_future,
        created_at=time.time()
    )
    
    # íì— ì‘ì—… ì œì¶œ
    try:
        await asyncio.wait_for(
            DB_WRITE_QUEUE.put(task), 
            timeout=5.0
        )
        logger.info(f"ì‘ì—… íì— ì œì¶œë¨: {task_id} (í í¬ê¸°: {DB_WRITE_QUEUE.qsize()})")
    except asyncio.TimeoutError:
        return {
            "success": False,
            "error": "í ì œì¶œ íƒ€ì„ì•„ì›ƒ"
        }
    
    # ê²°ê³¼ ëŒ€ê¸° (ìµœëŒ€ 60ì´ˆ)
    try:
        result = await asyncio.wait_for(result_future, timeout=60.0)
        logger.info(f"ì‘ì—… ì™„ë£Œ: {task_id}")
        return result
    except asyncio.TimeoutError:
        logger.error(f"ì‘ì—… íƒ€ì„ì•„ì›ƒ: {task_id}")
        return {
            "success": False,
            "error": "ì‘ì—… ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ"
        }


# í•œêµ­ ì‹œê°„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def get_kst_time() -> str:
    """í•œêµ­ ì‹œê°„ ë°˜í™˜ (ë¬¸ìì—´)"""
    kst = pytz.timezone('Asia/Seoul')
    return datetime.now(kst).strftime('%Y-%m-%d %H:%M:%S')

def get_kst_date() -> str:
    """í•œêµ­ ë‚ ì§œ ë°˜í™˜ (ë¬¸ìì—´)"""
    kst = pytz.timezone('Asia/Seoul')
    return datetime.now(kst).strftime('%Y.%m.%d')

def get_kst_timestamp() -> str:
    """í•œêµ­ ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜ (íŒŒì¼ëª…ìš©)"""
    kst = pytz.timezone('Asia/Seoul')
    return datetime.now(kst).strftime('%Y%m%d_%H%M%S')

def get_kst_datetime() -> datetime:
    """í•œêµ­ ì‹œê°„ datetime ê°ì²´ ë°˜í™˜"""
    kst = pytz.timezone('Asia/Seoul')
    return datetime.now(kst)

def get_kst_date_folder() -> str:
    """í•œêµ­ ì‹œê°„ ê¸°ì¤€ ë‚ ì§œ í´ë”ëª… ë°˜í™˜ (YYMMDD í˜•ì‹)"""
    kst = pytz.timezone('Asia/Seoul')
    return datetime.now(kst).strftime('%y%m%d')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',  # ë” ê°„ë‹¨í•œ í¬ë§·
    handlers=[
        logging.StreamHandler(sys.stdout),
        RotatingFileHandler('server.log', encoding='utf-8', maxBytes=50*1024*1024, backupCount=3)  # ë¡œê·¸ ë¡œí…Œì´ì…˜ ì¶”ê°€
    ]
)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Kakao Image Upload API",
    description="ì¹´ì¹´ì˜¤í†¡ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ì„œë²„",
    version="2.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì„¤ì • ìƒìˆ˜
KAKAO_IMAGE_DIR = Path("/Authfiles/kakao_images")
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
ALLOWED_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp'}
MAX_CONCURRENT_UPLOADS = 2000

# PostgreSQL ì„¤ì •
DATABASE_CONFIG = {
    "host": "dpg-d37aglogjchc73c45dh0-a.oregon-postgres.render.com",
    "database": "chatbot_ain6",
    "port": 5432,
    "user": "chatbot_ain6_user",
    "password": "QLC4mbPSwJuZR0LVvKZFhnjC80bCjacj"
}

# ì „ì—­ ë³€ìˆ˜
db_pool: Optional[AsyncConnectionPool] = None
image_counter: Dict[str, int] = {}  # ë™ì¼ ì‚¬ìš©ìì˜ ì´ë¯¸ì§€ ì¹´ìš´í„°

# ë””ë ‰í† ë¦¬ ìƒì„±
KAKAO_IMAGE_DIR.mkdir(parents=True, exist_ok=True)
logger.info(f"ì¹´ì¹´ì˜¤ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ í™•ì¸: {KAKAO_IMAGE_DIR.absolute()}")

# ë™ì‹œ ì—…ë¡œë“œ ì œí•œ
upload_semaphore = asyncio.Semaphore(MAX_CONCURRENT_UPLOADS)
logger.info(f"ë™ì‹œ ì—…ë¡œë“œ ì œí•œ: {MAX_CONCURRENT_UPLOADS}ê°œ")

async def init_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì´ˆê¸°í™”"""
    global db_pool
    try:
        # PostgreSQL ì—°ê²° ë¬¸ìì—´ ìƒì„±
        connection_string = f"postgresql://{DATABASE_CONFIG['user']}:{DATABASE_CONFIG['password']}@{DATABASE_CONFIG['host']}:{DATABASE_CONFIG['port']}/{DATABASE_CONFIG['database']}"
        
        db_pool = AsyncConnectionPool(
            connection_string,
            min_size=5,
            max_size=60,
            timeout=30
        )
        logger.info("PostgreSQL ì—°ê²° í’€ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        raise

async def close_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
    global db_pool
    if db_pool:
        await db_pool.close()
        logger.info("PostgreSQL ì—°ê²° í’€ ì¢…ë£Œ ì™„ë£Œ")

def validate_kakao_request(data: Dict[Any, Any]) -> bool:
    """ì¹´ì¹´ì˜¤í†¡ ìš”ì²­ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
    required_fields = [
        ("intent", ["id", "name"]),
        ("userRequest", ["timezone", "block", "utterance", "user"]),
        ("bot", ["id", "name"]),
        ("action", ["name", "id"])
    ]
    
    try:
        for field, sub_fields in required_fields:
            if field not in data:
                return False
            
            for sub_field in sub_fields:
                if sub_field not in data[field]:
                    return False
        
        # ì¤‘ìš”í•œ ì¤‘ì²© í•„ë“œë“¤ ê²€ì‚¬
        user_request = data["userRequest"]
        if "id" not in user_request["user"] or "type" not in user_request["user"]:
            return False
        if "id" not in user_request["block"] or "name" not in user_request["block"]:
            return False
            
        return True
    except (KeyError, TypeError):
        return False

def generate_unique_filename(username: str, user_id: str, extension: str = ".jpg") -> tuple[str, Path]:
    """
    ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„± ë° serial_numberë³„ í´ë” ê²½ë¡œ ë°˜í™˜
    Returns: (filename, full_directory_path)
    """
    global image_counter
    
    # serial_numberëŠ” user_idì˜ ì• 8ìë¦¬
    serial_number = user_id[:8]
    
    # ë‚ ì§œë³„ í´ë” ìƒì„± (YYMMDD í˜•ì‹)
    date_folder = get_kst_date_folder()
    
    # serial_numberë³„ í´ë” ê²½ë¡œ: /Authfiles/kakao_images/ë‚ ì§œ/serial_number
    serial_dir = KAKAO_IMAGE_DIR / date_folder / serial_number
    serial_dir.mkdir(parents=True, exist_ok=True)
    
    # ì‚¬ìš©ìë³„ ì¹´ìš´í„° í‚¤ ìƒì„±
    counter_key = f"{serial_number}_{date_folder}"
    
    # ì¹´ìš´í„° ì¦ê°€
    if counter_key not in image_counter:
        # í•´ë‹¹ í´ë”ì˜ ê¸°ì¡´ íŒŒì¼ë“¤ í™•ì¸í•˜ì—¬ ì¹´ìš´í„° ì´ˆê¸°í™”
        existing_files = list(serial_dir.glob(f"{serial_number}_*{extension}"))
        if existing_files:
            # ê°€ì¥ í° ì¸ë±ìŠ¤ ë²ˆí˜¸ ì°¾ê¸°
            max_idx = 0
            for file in existing_files:
                try:
                    # íŒŒì¼ëª…ì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ (serial_number_timestamp_idx.í™•ì¥ì)
                    parts = file.stem.split('_')
                    if len(parts) >= 3:
                        idx = int(parts[-1])  # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ì¸ë±ìŠ¤
                        max_idx = max(max_idx, idx)
                except (ValueError, IndexError):
                    continue
            image_counter[counter_key] = max_idx + 1
        else:
            image_counter[counter_key] = 1
    else:
        image_counter[counter_key] += 1
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
    timestamp = get_kst_timestamp()
    
    # íŒŒì¼ëª… ìƒì„±: serial_number_timestamp_idx.í™•ì¥ì
    filename = f"{serial_number}_{timestamp}_{image_counter[counter_key]}{extension}"
    
    return filename, serial_dir

def extract_image_urls_from_kakao_data(data: Dict[Any, Any]) -> List[str]:
    """ì¹´ì¹´ì˜¤í†¡ ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ URLë“¤ ì¶”ì¶œ"""
    urls = []
    
    try:
        # action > detailParamsì—ì„œ userimage ë°ì´í„° ì¶”ì¶œ
        detail_params = data.get("action", {}).get("detailParams", {})
        userimage_data = detail_params.get("userimage", {})
        
        # userimageì˜ valueê°€ JSON ë¬¸ìì—´ì¸ ê²½ìš°
        userimage_value = userimage_data.get("value", "")
        if userimage_value:
            try:
                # JSON íŒŒì‹±
                parsed_data = json.loads(userimage_value)
                secure_urls_str = parsed_data.get("secureUrls", "")
                
                if secure_urls_str:
                    # "List(...)" í˜•íƒœì—ì„œ URL ì¶”ì¶œ
                    if secure_urls_str.startswith("List(") and secure_urls_str.endswith(")"):
                        urls_content = secure_urls_str[5:-1]  # "List(" ì™€ ")" ì œê±°
                        url_pattern = r'https?://[^\s,)"\'\]]+(?:\?[^\s,)"\'\]]+)?'
                        found_urls = re.findall(url_pattern, urls_content)
                        urls.extend(found_urls)
                    else:
                        # ì§ì ‘ URL ë¬¸ìì—´ì¸ ê²½ìš°
                        url_pattern = r'https?://[^\s,)"\'\]]+(?:\?[^\s,)"\'\]]+)?'
                        found_urls = re.findall(url_pattern, secure_urls_str)
                        urls.extend(found_urls)
                        
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ë¬¸ìì—´ì—ì„œ ì§ì ‘ URL ì¶”ì¶œ
                url_pattern = r'https?://[^\s,)"\'\]]+(?:\?[^\s,)"\'\]]+)?'
                found_urls = re.findall(url_pattern, userimage_value)
                urls.extend(found_urls)
        
        # userimageì˜ originì—ì„œë„ í™•ì¸ (ë°±ì—…ìš©)
        userimage_origin = userimage_data.get("origin", "")
        if userimage_origin and "http" in userimage_origin:
            url_pattern = r'https?://[^\s,)"\'\]]+(?:\?[^\s,)"\'\]]+)?'
            found_urls = re.findall(url_pattern, userimage_origin)
            urls.extend(found_urls)
        
        # paramsì—ì„œë„ í™•ì¸ (ë°±ì—…ìš©)
        params = data.get("action", {}).get("params", {})
        userimage_param = params.get("userimage", "")
        if userimage_param and "http" in userimage_param:
            try:
                parsed_data = json.loads(userimage_param)
                secure_urls_str = parsed_data.get("secureUrls", "")
                if secure_urls_str:
                    url_pattern = r'https?://[^\s,)"\'\]]+(?:\?[^\s,)"\'\]]+)?'
                    found_urls = re.findall(url_pattern, secure_urls_str)
                    urls.extend(found_urls)
            except (json.JSONDecodeError, TypeError):
                url_pattern = r'https?://[^\s,)"\'\]]+(?:\?[^\s,)"\'\]]+)?'
                found_urls = re.findall(url_pattern, userimage_param)
                urls.extend(found_urls)
        
        # ì¤‘ë³µ ì œê±° ë° ë¹ˆ URL ì œê±°
        urls = list(set([url for url in urls if url and len(url) > 10]))
        
    except Exception as e:
        logger.error(f"URL ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    return urls

async def download_kakao_image(session: aiohttp.ClientSession, url: str, user_id: str, username: str) -> Dict[str, Any]:
    """ì¹´ì¹´ì˜¤í†¡ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥"""
    try:
        logger.info(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘ - ì‚¬ìš©ì: {username} ({user_id})")
        logger.info(f"ë‹¤ìš´ë¡œë“œ URL: {url}")
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
            if response.status != 200:
                logger.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status}")
                return {"status": "error", "error": f"HTTP {response.status}"}
            
            # Content-Type í™•ì¸
            content_type = response.headers.get('content-type', '')
            if not content_type.startswith('image/'):
                logger.error(f"ì´ë¯¸ì§€ê°€ ì•„ë‹Œ íŒŒì¼: {content_type}")
                return {"status": "error", "error": f"Invalid content type: {content_type}"}
            
            # ì´ë¯¸ì§€ ë°ì´í„° ì½ê¸°
            image_data = await response.read()
            
            if len(image_data) == 0:
                logger.error("ë¹ˆ ì´ë¯¸ì§€ íŒŒì¼")
                return {"status": "error", "error": "Empty image file"}
            
            if len(image_data) > MAX_FILE_SIZE:
                logger.error(f"íŒŒì¼ í¬ê¸° ì´ˆê³¼: {len(image_data):,} bytes")
                return {"status": "error", "error": f"File too large: {len(image_data):,} bytes"}
        
        # í™•ì¥ì ê²°ì • (Content-Type ê¸°ë°˜)
        extension = ".jpg"  # ê¸°ë³¸ê°’
        if "png" in content_type:
            extension = ".png"
        elif "gif" in content_type:
            extension = ".gif"
        elif "webp" in content_type:
            extension = ".webp"
        
        # íŒŒì¼ëª… ë° ê²½ë¡œ ìƒì„±
        filename, date_dir = generate_unique_filename(username, user_id, extension)
        file_path = date_dir / filename
        
        # íŒŒì¼ ì €ì¥
        async with aiofiles.open(file_path, 'wb') as f:
            await f.write(image_data)
        
        logger.info(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {file_path} ({len(image_data):,} bytes)")
        
        return {
            "status": "success",
            "filename": filename,
            "file_path": str(file_path),
            "file_size": len(image_data),
            "content_type": content_type,
            "original_url": url,
            "date_folder": date_dir.name
        }
        
    except asyncio.TimeoutError:
        logger.error("ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ")
        return {"status": "error", "error": "Download timeout"}
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return {"status": "error", "error": str(e)}
    
def format_request_summary_from_result(data: Dict[Any, Any], result: dict) -> str:
    """ìš”ì²­ ì •ë³´ë¥¼ ìš”ì•½ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    user_request = data["userRequest"]
    user_id = user_request["user"]["id"]
    serial_number = user_id[:8]

    summary = f"""ë³´ë‚´ì£¼ì‹  ì¸ì¦ì„œ({result['total_count']}ì¥)ì€ ì •ìƒì ìœ¼ë¡œ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ“©({get_kst_date()})

ğŸ”ˆê³ ìœ ë²ˆí˜¸ëŠ” [{serial_number}]ì…ë‹ˆë‹¤. 
(2025.09.22ë¶€í„° ì‹  ê³ ìœ ë²ˆí˜¸ ë°°ì •ì¤‘)

ğŸ°ìµœë¦½ìš° ì—°ìŠµìƒğŸ°ì„ ìœ„í•œ ì†Œì¤‘í•œ íˆ¬í‘œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.ğŸ¥°

âœ”ï¸9ì›” 19, 20, 21ì¼ì— ë°°ì •ëë˜ êµ¬ ê³ ìœ ë²ˆí˜¸(ì•ŒíŒŒë²³ëŒ€ë¬¸ì2+ìˆ«ì3) íˆ¬í‘œë„ ì •ìƒì ìœ¼ë¡œ ì§‘ê³„ë  ì˜ˆì •ì´ë‹ˆ, ê±±ì •í•˜ì§€ ì•Šìœ¼ì…”ë„ ë©ë‹ˆë‹¤.
âœ”ï¸ë˜í•œ ë‹¹ì²¨ì ë°œí‘œ í›„ ìˆœì°¨ì ìœ¼ë¡œ ê°œë³„ ì•ˆë‚´ê°€ ë°œì†¡ë©ë‹ˆë‹¤.

âœ”ï¸ì´ë²¤íŠ¸ ê´€ë ¨ ì•ˆë‚´ëŠ” ê³µì§€ì‚¬í•­ì„ í†µí•´ ì—…ë°ì´íŠ¸ ë˜ë‹ˆ, ë§ì€ ê´€ì‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤.""" 
    return summary

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸"""
    logger.info("=" * 60)
    logger.info("ì¹´ì¹´ì˜¤í†¡ ì´ë¯¸ì§€ ì—…ë¡œë“œ API ì„œë²„ ì‹œì‘")
    logger.info("=" * 60)
    logger.info(f"ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬: {KAKAO_IMAGE_DIR.absolute()}")
    logger.info(f"ìµœëŒ€ íŒŒì¼ í¬ê¸°: {MAX_FILE_SIZE // (1024*1024)}MB")
    logger.info(f"ì§€ì› íŒŒì¼ í˜•ì‹: {', '.join(ALLOWED_EXTENSIONS)}")
    logger.info(f"ìµœëŒ€ ë™ì‹œ ì—…ë¡œë“œ: {MAX_CONCURRENT_UPLOADS}ê°œ")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    await init_database()

    # í ì›Œì»¤ ì‹œì‘
    await start_queue_workers()
    
    logger.info(f"í ì„¤ì •: ì›Œì»¤ {QUEUE_WORKERS}ê°œ, ìµœëŒ€ í í¬ê¸° {DB_WRITE_QUEUE.maxsize}, ë°°ì¹˜ í¬ê¸° {BATCH_SIZE}")
    logger.info("=" * 60)

@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸"""
    logger.info("ì„œë²„ ì¢…ë£Œ ì¤‘...")

    # í ì›Œì»¤ ì¢…ë£Œ
    await stop_queue_workers()
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
    await close_database()
    
    logger.info("ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# í ìƒíƒœ ëª¨ë‹ˆí„°ë§ ê°œì„ 
@app.get("/queue/status")
async def queue_status():
    """í ìƒíƒœ í™•ì¸"""
    queue_size = DB_WRITE_QUEUE.qsize()
    queue_usage = (queue_size / DB_WRITE_QUEUE.maxsize) * 100
    
    return JSONResponse({
        "queue_size": queue_size,
        "max_queue_size": DB_WRITE_QUEUE.maxsize,
        "queue_usage_percent": round(queue_usage, 1),
        "status": "high" if queue_usage > 80 else "medium" if queue_usage > 50 else "normal",
        "workers_running": queue_workers_running,
        "active_workers": len(worker_tasks),
        "batch_size": BATCH_SIZE,
        "batch_timeout": BATCH_TIMEOUT,
        "db_pool_size": db_pool.get_stats() if db_pool else None
    })

@app.post("/kakao/chat")
async def process_kakao_request(request: Request):
    """ì¹´ì¹´ì˜¤í†¡ ì±—ë´‡ ìš”ì²­ ì²˜ë¦¬ ë° ì´ë¯¸ì§€ ì €ì¥ (íŠ¸ëœì­ì…˜ ë°©ì‹)"""
    try:
        # JSON ë°ì´í„° ë°›ê¸°
        data = await request.json()
        
        # ìš”ì²­ ì „ì²´ë¥¼ ë¡œê·¸ì— ì¶œë ¥ (ê°œë°œ/ë””ë²„ê¹…ìš©)
        # logger.info("="*80)
        # logger.info("ì¹´ì¹´ì˜¤í†¡ ìš”ì²­ ë°ì´í„°:")
        # logger.info(f"{json.dumps(data, indent=2, ensure_ascii=False)}")
        # logger.info("="*80)
        
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if not validate_kakao_request(data):
            logger.warning("ì˜ëª»ëœ ì¹´ì¹´ì˜¤í†¡ ìš”ì²­ í˜•ì‹")
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ìš”ì²­ í˜•ì‹ì…ë‹ˆë‹¤.")
        
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        user_request = data["userRequest"]
        user_id = user_request["user"]["id"]
                
        # ì´ë¯¸ì§€ URL ì¶”ì¶œ ë° ë‹¤ìš´ë¡œë“œ
        image_urls = extract_image_urls_from_kakao_data(data)
        
        if not image_urls:
            logger.warning(f"ì´ë¯¸ì§€ ì—†ìŒ: {user_id[:8]}")
            return {
                "version": "2.0",
                "template": {
                    "outputs": [{
                        "simpleText": {
                            "text": "ì´ë¯¸ì§€ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                        }
                    }]
                }
            }
        
        # ğŸ”¥ í ì‹œìŠ¤í…œìœ¼ë¡œ ì‘ì—… ì œì¶œ
        result = await submit_to_queue(user_id, '', image_urls, data)
        
        if not result["success"]:
            # ì‹¤íŒ¨ ì‘ë‹µ
            return {
                "version": "2.0",
                "template": {
                    "outputs": [{
                        "simpleText": {
                            "text": f"âŒ ì ‘ì† ì¦ê°€ë¡œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤.\n ì ì‹œí›„ ë‹¤ì‹œ ì¸ì¦ì„œë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”."
                        }
                    }]
                }
            }
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ìƒì„±
        response_text = format_request_summary_from_result(data, result)
        
        logger.info(f"ì¹´ì¹´ì˜¤í†¡ ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ - ì‚¬ìš©ì: {user_id}, ì´ë¯¸ì§€: {result['success_count']}/{result['total_count']}ê°œ, DBì €ì¥: {result['saved_to_db_count']}ê°œ")
        
        # ì¹´ì¹´ì˜¤í†¡ í‘œì¤€ ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": response_text
                        }
                    }
                ]
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì¹´ì¹´ì˜¤í†¡ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        return {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                        }
                    }
                ]
            }
        }

async def save_image_upload_to_db_in_transaction(
    conn,  # psycopg connection object
    username: str,
    original_url: str, 
    user_id: str,
    image_data: Dict[str, Any]
) -> bool:
    """íŠ¸ëœì­ì…˜ ë‚´ì—ì„œ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    
    serial_number = user_id[:8]

    insert_sql = """
    INSERT INTO kakao_image_uploads (
        username, serial_number, user_id, original_url, filename, file_path, 
        file_size, content_type, upload_time
    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
    """
    
    try:
        await conn.execute(
            insert_sql,
            (
                username,
                serial_number,
                user_id,
                original_url,
                image_data["filename"],
                image_data["file_path"],
                image_data["file_size"],
                image_data["content_type"],
                get_kst_time()
            )
        )
        logger.info(f"DB ì €ì¥ ì™„ë£Œ (íŠ¸ëœì­ì…˜): {image_data['filename']}")
        return True
    except Exception as e:
        logger.error(f"DB ì €ì¥ ì‹¤íŒ¨ (íŠ¸ëœì­ì…˜): {str(e)}")
        return False
    
async def cleanup_files(file_paths: list):
    """íŒŒì¼ ì •ë¦¬ í•¨ìˆ˜ (ë¡¤ë°±ìš©)"""
    for file_path in file_paths:
        try:
            if file_path and Path(file_path).exists():
                Path(file_path).unlink()
                logger.info(f"ë¡¤ë°±: íŒŒì¼ ì‚­ì œ - {file_path}")
        except Exception as e:
            logger.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ - {file_path}: {str(e)}")

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬"""
    # DB ì—°ê²° ìƒíƒœ í™•ì¸
    db_status = "connected" if db_pool else "disconnected"
    
    return JSONResponse({
        "status": "healthy",
        "timestamp": get_kst_datetime().isoformat(),
        "current_date_folder": get_kst_date_folder(),
        "kakao_image_dir": str(KAKAO_IMAGE_DIR),
        "max_file_size_mb": MAX_FILE_SIZE // (1024*1024),
        "allowed_extensions": list(ALLOWED_EXTENSIONS),
        "database_status": db_status
    })

@app.get("/")
async def root():
    """ë£¨íŠ¸ ê²½ë¡œ"""
    return JSONResponse({
        "message": "ì¹´ì¹´ì˜¤í†¡ ì´ë¯¸ì§€ ì—…ë¡œë“œ API ì„œë²„",
        "version": "2.0.0",
        "current_date_folder": get_kst_date_folder(),
        "endpoints": {
            "kakao_chat": "/kakao/chat",
            "health_check": "/health",
            "api_docs": "/docs"
        }
    })

if __name__ == "__main__":
    import uvicorn
    
    print("=" * 70)
    print("ì¹´ì¹´ì˜¤í†¡ ì´ë¯¸ì§€ ì—…ë¡œë“œ API ì„œë²„ ì‹œì‘")
    print("=" * 70)
    print(f"ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬: {KAKAO_IMAGE_DIR.absolute()}")
    print(f"ì˜¤ëŠ˜ ë‚ ì§œ í´ë”: {get_kst_date_folder()}")
    print(f"ìµœëŒ€ íŒŒì¼ í¬ê¸°: {MAX_FILE_SIZE // (1024*1024)}MB")
    print(f"ì§€ì› íŒŒì¼ í˜•ì‹: {', '.join(ALLOWED_EXTENSIONS)}")
    print(f"ìµœëŒ€ ë™ì‹œ ì—…ë¡œë“œ: {MAX_CONCURRENT_UPLOADS}ê°œ")
    print("=" * 70)
    print("ì„œë²„ ì£¼ì†Œ:")
    print("   - ë©”ì¸: http://localhost:8000")
    print("   - API ë¬¸ì„œ: http://localhost:8000/docs")
    print("   - í—¬ìŠ¤ì²´í¬: http://localhost:8000/health")
    print("=" * 70)
    print("ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸:")
    print("   - POST /kakao/chat : ì¹´ì¹´ì˜¤í†¡ ì±—ë´‡ ì‘ë‹µ")
    print("   - GET  /health     : í—¬ìŠ¤ì²´í¬")
    print("=" * 70)
    print("ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
    print("=" * 70)
    
    try:
        uvicorn.run(
            "main:app",
            host="0.0.0.0",
            port=8000,
            workers=17,
            reload=True,
            log_level="info"
        )
    except KeyboardInterrupt:
        print("\n" + "=" * 70)
        print("ì„œë²„ê°€ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("=" * 70)